# TÃ¼rkÃ§e Duygu Analizi - Transformer Modelleri KarÅŸÄ±laÅŸtÄ±rmasÄ±

TÃ¼rkÃ§e metinler Ã¼zerinde duygu analizi yapmak iÃ§in Ã§eÅŸitli Transformer tabanlÄ± modellerin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±ran kapsamlÄ± bir makine Ã¶ÄŸrenmesi projesi.

## ğŸ¯ Proje HakkÄ±nda

Bu proje, TÃ¼rkÃ§e metinlerdeki duygularÄ± (pozitif, negatif, nÃ¶tr) tespit etmek iÃ§in Ã¼Ã§ farklÄ± Transformer modelinin performansÄ±nÄ± analiz eder. Ã‡alÄ±ÅŸma, farklÄ± veri boyutlarÄ±nda (5.000 - 20.000 Ã¶rnek) model performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rarak en uygun model ve veri setini belirlemeyi amaÃ§lar.

### Temel Ã–zellikler
- âœ… Dengeli veri seti Ã¶rneklemesi
- âœ… TÃ¼rkÃ§eye Ã¶zel metin Ã¶n iÅŸleme
- âœ… GPU hÄ±zlandÄ±rma desteÄŸi (Tesla T4)
- âœ… KapsamlÄ± performans metrikleri
- âœ… Epoch bazlÄ± detaylÄ± izleme

## ğŸ¤– KullanÄ±lan Modeller

### 1. XLM-RoBERTa Base
- **Model:** `FacebookAI/xlm-roberta-base`
- **AÃ§Ä±klama:** Ã‡ok dilli RoBERTa modeli, 100 farklÄ± dili destekler
- **AvantajlarÄ±:** Cross-lingual transfer learning

### 2. BERTurk
- **Model:** `dbmdz/bert-base-turkish-cased`
- **AÃ§Ä±klama:** TÃ¼rkÃ§e iÃ§in Ã¶zel eÄŸitilmiÅŸ BERT modeli
- **AvantajlarÄ±:** TÃ¼rkÃ§e dil yapÄ±sÄ±na optimize

### 3. DistilBERTurk
- **Model:** `dbmdz/distilbert-base-turkish-cased`
- **AÃ§Ä±klama:** BERTurk'Ã¼n hafif ve hÄ±zlÄ± versiyonu
- **AvantajlarÄ±:** %40 daha kÃ¼Ã§Ã¼k, %60 daha hÄ±zlÄ±

## ğŸ“Š Veri Seti

### Kaynak
- **Dataset:** `winvoker/turkish-sentiment-analysis-dataset`
- **Platform:** Hugging Face
- **Orijinal Boyut:** 40.000+ Ã¶rnek

### SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±
Dengeli Ã¶rnekleme ile her sÄ±nÄ±ftan eÅŸit sayÄ±da veri:

### Deneysel Veri BoyutlarÄ±
- 5.000 Ã¶rnek
- 10.000 Ã¶rnek
- 15.000 Ã¶rnek
- 20.000 Ã¶rnek

## ğŸ› ï¸ Kurulum

### Google Colab Ãœzerinde Ã‡alÄ±ÅŸtÄ±rma
1. Notebook'u Google Colab'a yÃ¼kleyin
2. Runtime > Change runtime type > GPU (T4) seÃ§in
3. TÃ¼m hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n

## ğŸš€ KullanÄ±m

### 1. Veri YÃ¼kleme
```python
from datasets import load_dataset

dataset = load_dataset("winvoker/turkish-sentiment-analysis-dataset")
df = dataset['train'].to_pandas()
```

### 2. Veri Temizleme
```python
# Otomatik temizleme fonksiyonu
temiz_metin = veri_temizleme(metin)
```

Temizleme adÄ±mlarÄ±:
- KÃ¼Ã§Ã¼k harfe Ã§evirme
- KullanÄ±cÄ± adÄ± temizleme (@mentions)
- Noktalama ve sayÄ± kaldÄ±rma
- TÃ¼rkÃ§e stopwords temizliÄŸi
- Stemming (kÃ¶k bulma)

### 3. Model EÄŸitimi
```python
# Ã–rnek: XLM-RoBERTa ile eÄŸitim
model = AutoModelForSequenceClassification.from_pretrained(
    "FacebookAI/xlm-roberta-base", 
    num_labels=3
)

training_args = TrainingArguments(
    num_train_epochs=3,
    per_device_train_batch_size=16,
    evaluation_strategy="epoch"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset
)

trainer.train()
```

## ğŸ“ˆ Metodoloji

### Veri Ã–n Ä°ÅŸleme SÃ¼reci
1. **Metin NormalleÅŸtirme**
   - TÃ¼m metinler kÃ¼Ã§Ã¼k harfe Ã§evrilir
   - Ã–zel karakterler ve noktalama iÅŸaretleri kaldÄ±rÄ±lÄ±r

2. **Stopwords TemizliÄŸi**
   - NLTK TÃ¼rkÃ§e stopwords listesi kullanÄ±lÄ±r
   - AnlamsÄ±z kelimeler filtrelenir

3. **Stemming**
   - TurkishStemmer ile kelime kÃ¶klerine indirgeme
   - Kelime Ã§eÅŸitliliÄŸini azaltma

4. **Tokenizasyon**
   - Model-spesifik tokenizer'lar kullanÄ±lÄ±r
   - Max length: 128 token
   - Padding ve truncation uygulanÄ±r

### EÄŸitim Parametreleri
- **Epoch:** 3
- **Batch Size:** 16
- **Learning Rate:** Otomatik (AdamW)
- **Train/Test Split:** 80/20
- **Evaluation Strategy:** Her epoch sonunda

### Performans Metrikleri
- **Accuracy:** Genel doÄŸruluk oranÄ±
- **F1-Score:** Precision ve Recall'Ä±n harmonik ortalamasÄ±
- **Precision:** Pozitif tahminlerin doÄŸruluÄŸu
- **Recall:** GerÃ§ek pozitifleri bulma oranÄ±
- **Loss:** Training ve Validation loss

## ğŸ“Š SonuÃ§lar

### 5.000 Veri ile SonuÃ§lar (3. Epoch)
| Model | Accuracy | F1-Score | Precision | Recall |
|-------|----------|----------|-----------|--------|
| XLM-RoBERTa | 0.8040 | 0.8029 | 0.8022 | 0.8040 |
| BERTurk | **0.8710** | **0.8708** | **0.8707** | **0.8710** |
| DistilBERTurk | 0.8690 | 0.8680 | 0.8678 | 0.8690 |

### 10.000 Veri ile SonuÃ§lar (3. Epoch)
| Model | Accuracy | F1-Score | Precision | Recall |
|-------|----------|----------|-----------|--------|
| XLM-RoBERTa | 0.8665 | 0.8658 | 0.8656 | 0.8665 |
| BERTurk | **0.9070** | **0.9067** | **0.9065** | **0.9070** |
| DistilBERTurk | 0.8775 | 0.8769 | 0.8767 | 0.8775 |

### 15.000 Veri ile SonuÃ§lar (3. Epoch)
| Model | Accuracy | F1-Score | Precision | Recall |
|-------|----------|----------|-----------|--------|
| XLM-RoBERTa | 0.8710 | 0.8701 | 0.8698 | 0.8710 |
| BERTurk | **0.9037** | **0.9034** | **0.9034** | **0.9037** |
| DistilBERTurk | 0.8800 | 0.8794 | 0.8790 | 0.8800 |

### 20.000 Veri ile SonuÃ§lar (3. Epoch)
| Model | Accuracy | F1-Score | Precision | Recall |
|-------|----------|----------|-----------|--------|
| XLM-RoBERTa | 0.8892 | 0.8888 | 0.8886 | 0.8892 |
| BERTurk | **0.9130** | **0.9130** | **0.9130** | **0.9130** |
| DistilBERTurk | 0.8938 | 0.8936 | 0.8935 | 0.8938 |

### Temel Bulgular

#### ğŸ† En Ä°yi Performans: BERTurk
- TÃ¼m veri boyutlarÄ±nda en yÃ¼ksek accuracy
- 20.000 veri ile **%91.3 accuracy** (en yÃ¼ksek performans)
- TÃ¼rkÃ§e dil yapÄ±sÄ±na Ã¶zgÃ¼ eÄŸitim avantajÄ±
- F1-Score'da tutarlÄ± Ã¼stÃ¼nlÃ¼k

#### âš¡ En HÄ±zlÄ± Model: DistilBERTurk
- BERTurk'e yakÄ±n performans (%89.4 ile %91.3 arasÄ±nda)
- ~%50 daha hÄ±zlÄ± eÄŸitim sÃ¼resi
- Ãœretim ortamlarÄ± iÃ§in ideal alternatif

#### ğŸŒ Ã‡ok Dilli Alternatif: XLM-RoBERTa
- Kabul edilebilir performans (%80-89 arasÄ±)
- Cross-lingual transfer learning
- Ã‡ok dilli projelerde kullanÄ±labilir

### Veri Boyutu Etkisi
- **5.000 â†’ 10.000:** Ortalama **~5-6% performans artÄ±ÅŸÄ±** (en bÃ¼yÃ¼k sÄ±Ã§rama)
- **10.000 â†’ 15.000:** Ortalama **~0.5% performans artÄ±ÅŸÄ±** (dÃ¼ÅŸÃ¼ÅŸ)
- **15.000 â†’ 20.000:** Ortalama **~1.5% performans artÄ±ÅŸÄ±**
- **Optimal veri boyutu:** 20.000 Ã¶rnek (maksimum performans iÃ§in)
- **Maliyet-Etkin seÃ§im:** 10.000 Ã¶rnek (iyi performans/hÄ±z dengesi)

### Model Performans GeliÅŸimi (Veri Boyutuna GÃ¶re)

**BERTurk GeliÅŸimi:**
- 5K: 87.1% â†’ 10K: 90.7% â†’ 15K: 90.4% â†’ 20K: **91.3%**
- En stabil ve tutarlÄ± performans

**DistilBERTurk GeliÅŸimi:**
- 5K: 86.9% â†’ 10K: 87.8% â†’ 15K: 88.0% â†’ 20K: **89.4%**
- BERTurk'e en yakÄ±n performans/hÄ±z dengesi

**XLM-RoBERTa GeliÅŸimi:**
- 5K: 80.4% â†’ 10K: 86.7% â†’ 15K: 87.1% â†’ 20K: **88.9%**
- En bÃ¼yÃ¼k geliÅŸim gÃ¶sterdi (5K'dan 20K'ya +8.5%)

## ğŸ”¬ Teknolojiler

### KÃ¼tÃ¼phaneler
- **Transformers:** Hugging Face model hub
- **PyTorch:** Deep learning framework
- **Datasets:** Veri yÃ¼kleme ve iÅŸleme
- **scikit-learn:** Metrikler ve train/test split
- **NLTK:** TÃ¼rkÃ§e NLP iÅŸlemleri
- **TurkishStemmer:** TÃ¼rkÃ§e kÃ¶k bulma

### AraÃ§lar
- **Google Colab:** GPU-accelerated notebook ortamÄ±
- **Weights & Biases:** Devre dÄ±ÅŸÄ± (opsiyonel tracking)
- **Matplotlib & Seaborn:** GÃ¶rselleÅŸtirme

## ğŸ“ Proje YapÄ±sÄ±

```
dataSci_Proje_4.ipynb
â”œâ”€â”€ 1. Veri Seti Ã‡ekme ve KÃ¼tÃ¼phane Kurulumu
â”œâ”€â”€ 2. Veri Temizleme Fonksiyonu
â”œâ”€â”€ 3. Veri YÃ¼kleme ve Ä°nceleme
â”œâ”€â”€ 4. Etiket DÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve Veri BÃ¶lme
â”œâ”€â”€ 5. Model EÄŸitimi
â”‚   â”œâ”€â”€ 5.1 XLM-RoBERTa (5k, 10k, 15k, 20k)
â”‚   â”œâ”€â”€ 5.2 BERTurk (5k, 10k, 15k, 20k)
â”‚   â””â”€â”€ 5.3 DistilBERTurk (5k, 10k, 15k, 20k)
â””â”€â”€ 6. SonuÃ§ Analizi ve KarÅŸÄ±laÅŸtÄ±rma
```

## ğŸ’¡ Ã–neriler

### Ãœretim OrtamÄ± Ä°Ã§in
1. **YÃ¼ksek DoÄŸruluk Ã–nceliÄŸi:** BERTurk kullanÄ±n
2. **HÄ±z Ã–nceliÄŸi:** DistilBERTurk kullanÄ±n
3. **Ã‡ok Dilli Destek:** XLM-RoBERTa kullanÄ±n

### Ä°yileÅŸtirme Fikirleri
- [ ] Hyperparameter tuning (learning rate, batch size)
- [ ] Data augmentation teknikleri
- [ ] Ensemble model yaklaÅŸÄ±mÄ±
- [ ] Fine-tuning iÃ§in domain-specific veri
- [ ] Class imbalance handling (weighted loss)
- [ ] Cross-validation implementasyonu

## ğŸ“ Lisans

Bu proje eÄŸitim amaÃ§lÄ± geliÅŸtirilmiÅŸtir.

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici

**Furkan Poyraz**
- Computer Engineering Student
- Machine Learning & NLP Enthusiast

## ğŸ™ TeÅŸekkÃ¼rler

- Hugging Face ekibine Transformers kÃ¼tÃ¼phanesi iÃ§in
- dbmdz ekibine BERTurk modelleri iÃ§in
- winvoker'a TÃ¼rkÃ§e sentiment analysis dataset iÃ§in

---

**Not:** Bu proje Google Colab Ã¼zerinde Tesla T4 GPU ile test edilmiÅŸtir. FarklÄ± ortamlarda performans sÃ¼releri deÄŸiÅŸiklik gÃ¶sterebilir.
